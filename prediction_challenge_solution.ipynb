{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "prediction_challenge_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lEtpbsTkxEaV"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T1M0THY1337/big-data-prediction-challenge/blob/master/prediction_challenge_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNapCUQ9tj-C",
        "colab_type": "text"
      },
      "source": [
        "# Prediction Challange by Sebastian and Tim\n",
        "\n",
        "Your job is to predict whether or not a person will become a customer of a bank. The data itself contains basic demographic information about numerous  customers as well as data related to phone-based marketing calls during specific campaigns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEtpbsTkxEaV",
        "colab_type": "text"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_8CKo6vuiKW",
        "colab_type": "text"
      },
      "source": [
        "## Version 0.1\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**2020-01-29** Feature Engineering (Date), Hyperparameter Tuning\\\n",
        "**2020-01-24** Start mit dem Minimum Working Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYyRmTQNtj-F",
        "colab_type": "text"
      },
      "source": [
        "## Data Dictionary\n",
        "\n",
        "<table style=\"width: 100%;\">\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th style=\"width: 30%; text-align: left;\">Feature</th>\n",
        "            <th style=\"width: 70%; text-align: left;\">Description</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td>date</td>\n",
        "            <td>The last contact date</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>age</td>\n",
        "            <td>The age of the customer</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>marital_status</td>\n",
        "            <td>The marital status of the customer</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>education</td>\n",
        "            <td>The educationan of the customer</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>job</td>\n",
        "            <td>The type of job of the customer</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>credit_default</td>\n",
        "            <td>Whether or not the customer has a credit in default</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>housing_loan</td>\n",
        "            <td>Whether or not the customer has a housing loan</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>personal_loan</td>\n",
        "            <td>Whether or not the customer has a personal loan</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>communication_type</td>\n",
        "            <td>The type of contact communication</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>n_contacts_campaign</td>\n",
        "            <td>The number of contacts performed during this marketing campaign and for this customer</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>days_since_last_contact</td>\n",
        "            <td>The number of days passed by after the customer was last contacted from a previous domain</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>n_contacts_before</td>\n",
        "            <td>The number of contacts performed before this marketing campaign and for this customer</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>previous_conversion</td>\n",
        "            <td>Whether or not the customer has been a customer before</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>success</td>\n",
        "            <td>Whether or not the customer became an actual customer (target variable)</td>\n",
        "        </tr>\n",
        "    </tbody>   \n",
        "</table>   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-ZH8xKaxLGH",
        "colab_type": "text"
      },
      "source": [
        "# Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGyVwYL-tj-H",
        "colab_type": "text"
      },
      "source": [
        "## Package Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNkzZA6xtj-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import sys as sys\n",
        "import csv, datetime\n",
        "from datetime import datetime\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRXDmV7stj-W",
        "colab_type": "text"
      },
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL64eb7ztj-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/' +\n",
        "    'master/datasets/prediction-challenge/dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "prediction_dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/' +\n",
        "    'master/datasets/prediction-challenge/prediction-dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxVLYLqEtj-v",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R43QutQtj-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create some new features based on the given features\n",
        "# or enrich the dataset with features from datasets.\n",
        "# dataset.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYdqBNps5P1A",
        "colab": {}
      },
      "source": [
        "d# ataset.apply?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-qz5y9cTYOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getYear(inDate):\n",
        "  return inDate.year\n",
        "def getMonth(inDate):\n",
        "  return inDate.month\n",
        "def getWeekday(inDate):\n",
        "  return inDate.weekday\n",
        "def getWeekendDay(inDate):\n",
        "  if (inDate.weekday == 'Saturday') or (inDate.weekday == 'Sunday'):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "dataset.insert(1, \"dateYear\", dataset['date'], allow_duplicates=True)\n",
        "dataset.insert(2, \"dateMonth\", dataset['date'], allow_duplicates=True)\n",
        "dataset.insert(3, \"dateWeekday\", dataset['date'], allow_duplicates=True)\n",
        "dataset.insert(4, \"dateWeekendDay\", dataset['date'], allow_duplicates=True)\n",
        "\n",
        "# dataset.dateYear = dataset.dateYear.apply(getYear)\n",
        "# dataset.dateMonth = dataset.dateMonth.apply(getMonth)\n",
        "\n",
        "dataset.dateYear = dataset['dateYear'].dt.year\n",
        "dataset.dateMonth = dataset['dateMonth'].dt.month\n",
        "dataset.dateWeekday = dataset['dateWeekday'].dt.weekday_name\n",
        "dataset.dateWeekendDay = dataset.dateWeekendDay.apply(getWeekendDay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp3fP_IR50u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset.loc[dataset['dateWeekendDay'] == True]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzCHihLktj-6",
        "colab_type": "text"
      },
      "source": [
        "## Model, Pipeline and Scoring Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXtb--5Ytj--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset[['date', 'age', 'marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'communication_type', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before', 'previous_conversion', 'duration']]\n",
        "\n",
        "X = dataset[['dateYear', 'dateMonth', 'dateWeekday', 'age', 'marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'communication_type', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before', 'previous_conversion', 'duration']]\n",
        "y = dataset['success']\n",
        "\n",
        "# data_dmatrix = xgb.DMatrix(data=X,label=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0f-nV_LS2Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb.XGBClassifier?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtICuwCbtj_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparams = {\n",
        "#     'loss': 'log', 'penalty': 'l2', 'alpha': 0.0001, 'max_iter': 1000, 'tol': 1e-3, \n",
        "#     'n_jobs': -1, 'random_state': 1909, 'learning_rate': 'invscaling', 'eta0': 0.01}\n",
        "# classifier = SGDClassifier(**hyperparams)\n",
        "\n",
        "x_reg_alpha = 0\n",
        "x_reg_lambda = 0.001\n",
        "x_rscv = 10\n",
        "x_random_state = 1909\n",
        "x_n_estimators_min = 100\n",
        "x_n_estimators_max = 500\n",
        "x_max_depth_min = 1\n",
        "x_max_depth_max = 10\n",
        "x_rsLearningRate = 0.001\n",
        "classifier = xgb.XGBClassifier(n_jobs=-1, random_state=x_random_state, objective='binary:logistic', reg_lambda=x_reg_lambda, reg_alpha=x_reg_alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhSvZBZ1tj_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scorer = make_scorer(f1_score, pos_label='Yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwLNxvgTtj_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = ['age', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before', 'duration']\n",
        "numeric_transformer = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "])\n",
        "\n",
        "categorical_features = ['dateYear', 'dateMonth', 'dateWeekday', 'marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'communication_type', 'previous_conversion']\n",
        "categorical_transformer = Pipeline([\n",
        "    ('onehotencoder', OneHotEncoder(drop='first')),\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('numeric_transformer', numeric_transformer, numeric_features),\n",
        "    ('categorical_transformer', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('classifier', classifier)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWSA_Sf_GljZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# xgb.XGBClassifier?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RglM927Qtj_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators = randint(x_n_estimators_min, x_n_estimators_max)\n",
        "max_depth = randint(x_max_depth_min, x_max_depth_max)\n",
        "param_distributions = {'classifier__n_estimators': n_estimators, 'classifier__max_depth': max_depth, 'classifier__learning_rate': uniform(0, x_rsLearningRate)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqfj0QvsBUVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RandomizedSearchCV?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-cGOMygtj_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search = RandomizedSearchCV(\n",
        "    pipeline, param_distributions=param_distributions, n_iter=3, scoring=scorer, \n",
        "    n_jobs=-1, cv=x_rscv, random_state=x_random_state, return_train_score=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osUP_vO-tj_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search = search.fit(X, y)\n",
        "# classifier.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD1RC9osIEE6",
        "colab_type": "code",
        "outputId": "3e30d858-bdd1-4b89-de90-ee14498d7e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "f'Optimal parameters: {search.best_params_}'"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Optimal parameters: {'classifier__learning_rate': 0.0006699737886943773, 'classifier__max_depth': 6, 'classifier__n_estimators': 266}\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTxta8l6tkAB",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_G8-du6tkAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_score = search.cv_results_['mean_train_score'][search.best_index_] * 100\n",
        "test_score = search.cv_results_['mean_test_score'][search.best_index_] * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d_TYdu0tkAG",
        "colab_type": "code",
        "outputId": "1cb41bd3-bea9-4a6a-9547-07ef02b68d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f'Mean F1 Score (Training/Test): {training_score:.2f}%/{test_score:.2f}%'"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mean F1 Score (Training/Test): 60.21%/57.63%'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olehKm5BEKqq",
        "colab_type": "text"
      },
      "source": [
        "### Optional (k-Cross Validation Gegencheck)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIxcBapqEO2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = xgb.XGBClassifier(n_estimators=search.best_params_['classifier__n_estimators'], \n",
        "                          max_depth=search.best_params_['classifier__max_depth'],\n",
        "                          learning_rate=search.best_params_['classifier__learning_rate'],\n",
        "                          random_state=x_random_state,\n",
        "                          n_jobs=-1,\n",
        "                          reg_alpha=0.0001)\n",
        "\n",
        "pipeline2 = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('model', model),\n",
        "])\n",
        "\n",
        "# pipeline2 = pipeline2.fit(X, y)\n",
        "# res_cv = cross_validate(pipeline2, X, y, scoring=scorer, cv=10, return_train_score=True)\n",
        "# res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
        "# res_f1_te = np.mean(res_cv['test_score']) * 100\n",
        "# print(f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}/{res_f1_te:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCp1lI-9h9c",
        "colab_type": "text"
      },
      "source": [
        "## Log Datei füttern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEWS-tsj9hhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datetime;alpha;lambda;random_state;n_estimators_min;n_estimators_max;max_depth_min;x_max_depth_max;best_n_estimators;best_max_depth;best_learning_rate;f1_training;f1_test;std_train_score;std_test_score\n",
        "\n",
        "logData = [[datetime.now()\n",
        "           ,x_reg_alpha\n",
        "           ,x_reg_lambda\n",
        "           ,x_random_state\n",
        "           ,x_n_estimators_min\n",
        "           ,x_n_estimators_max\n",
        "           ,x_max_depth_min\n",
        "           ,x_max_depth_max\n",
        "           ,x_rsLearningRate\n",
        "           ,search.best_params_['classifier__n_estimators']\n",
        "           ,search.best_params_['classifier__max_depth']\n",
        "           ,search.best_params_['classifier__learning_rate']\n",
        "           ,training_score\n",
        "           ,test_score\n",
        "           ,search.cv_results_['std_train_score'][search.best_index_]\n",
        "           ,search.cv_results_['std_test_score'][search.best_index_]]]\n",
        "with open('log.csv', 'a') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=';')\n",
        "    writer.writerows(logData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce1oD7CDtkAO",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njPYhiz5tkAS",
        "colab_type": "code",
        "outputId": "6b26c0c3-b081-41ec-d8cc-f657f88dd38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "sys.exit()\n",
        "predictions = search.best_estimator_.predict(prediction_dataset)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6H61WM5tkAZ",
        "colab_type": "text"
      },
      "source": [
        "## Submission Dataset Preparation\n",
        "\n",
        "Your upload to the Online-Campus should contain your written report (the actual seminar paper), this notebook as file as well as the generated submission dataset with your predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwJtq1XltkAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(\n",
        "    predictions, index=prediction_dataset.index, columns=['prediction'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PFaGgAjtkAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matriculation_number = '12345678'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Rd5zVutkAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(\n",
        "    f'./submission-{matriculation_number}.csv', index_label='identifier')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16tuFXaYwPmR",
        "colab_type": "text"
      },
      "source": [
        "# Nützliche Links\n",
        "* XGboost Implementation: [https://www.datacamp.com/community/tutorials/xgboost-in-python](https://www.datacamp.com/community/tutorials/xgboost-in-python)\n",
        "* XGBoost Parameter List: [https://xgboost.readthedocs.io/en/latest/parameter.html](https://xgboost.readthedocs.io/en/latest/parameter.html)"
      ]
    }
  ]
}